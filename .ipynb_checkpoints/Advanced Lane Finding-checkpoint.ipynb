{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c9c7e3",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines Finding Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0350a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d6410",
   "metadata": {},
   "source": [
    "## Camera calibration matrix and distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cdaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration():\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = mpimg.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            calibrated_img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            mpimg.imsave('output_images/calibration/' + fname[10:], calibrated_img)\n",
    "            \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return mtx, dist\n",
    "\n",
    "\n",
    "def distortion_correction(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85c73362",
   "metadata": {},
   "source": [
    "imgs = os.listdir('test_images/')\n",
    "\n",
    "for img in imgs:\n",
    "    dist_img = mpimg.imread('test_images/' + img)\n",
    "    mtx, dist = calibration()\n",
    "    undist = distortion_correction(dist_img, mtx, dist)\n",
    "    \n",
    "    mpimg.imsave('output_images/distortion_correction/' + img, undist)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8dad0ac",
   "metadata": {},
   "source": [
    "imgs = os.listdir('output_images/calibration/')\n",
    "\n",
    "for img in imgs:\n",
    "    dist_img = mpimg.imread('output_images/calibration/' + img)\n",
    "    mtx, dist = calibration()\n",
    "    undist = distortion_correction(dist_img, mtx, dist)\n",
    "    \n",
    "    mpimg.imsave('output_images/distortion_correction_chess/' + img, undist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e1aea",
   "metadata": {},
   "source": [
    "## Thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(image, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobel_parameter = [1, 0]\n",
    "    elif orient == 'y':\n",
    "        sobel_parameter = [0, 1]\n",
    "    else:\n",
    "        return \"Wrong Orient\"\n",
    "        \n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, sobel_parameter[0], sobel_parameter[1], ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    return grad_binary\n",
    "\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "\n",
    "    mag_binary = np.zeros_like(scaled_mag)\n",
    "    mag_binary[(scaled_mag >= mag_thresh[0]) & (scaled_mag <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return mag_binary\n",
    "\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    dir_binary = np.zeros_like(dir_grad)\n",
    "    dir_binary[(dir_grad >= thresh[0]) & (dir_grad <= thresh[1])] = 1\n",
    "    \n",
    "    return dir_binary\n",
    "\n",
    "\n",
    "def color_select(image, r_thresh=(0, 255), g_thresh=(0, 255), l_thresh=(0, 255), s_thresh=(0, 255)):\n",
    "    r_channel = image[:,:,0]\n",
    "    g_channel = image[:,:,1]\n",
    "    \n",
    "    r_binary = np.zeros_like(r_channel)\n",
    "    r_binary[(r_channel > r_thresh[0]) & (r_channel <= r_thresh[1])] = 1\n",
    "    \n",
    "    g_binary = np.zeros_like(g_channel)\n",
    "    g_binary[(g_channel > g_thresh[0]) & (g_channel <= g_thresh[1])] = 1\n",
    "    \n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel > l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    \n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel > s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    return r_binary, g_binary, l_binary, s_binary\n",
    "\n",
    "\n",
    "def combined_color_threshold(image):\n",
    "    blur_img = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "    r_binary, g_binary, l_binary, s_binary = \\\n",
    "    color_select(blur_img, r_thresh=(150, 255), g_thresh=(150, 255), l_thresh=(120, 255), s_thresh=(100, 255))\n",
    "    \n",
    "    # Sobel kernal size\n",
    "    ksize = 3 \n",
    "    \n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(blur_img, orient='x', sobel_kernel=ksize, thresh=(40, 200))\n",
    "\n",
    "    dir_binary = dir_threshold(blur_img, sobel_kernel=ksize, thresh=(np.pi/6, np.pi/2))\n",
    "\n",
    "    combined_thresh = np.zeros_like(dir_binary)\n",
    "    combined_thresh[((gradx == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    combined_color = np.zeros_like(r_binary)\n",
    "    combined_color[(r_binary == 1) & (g_binary == 1) & (l_binary == 1)] = 1\n",
    "    \n",
    "    combined_binary = np.zeros_like(combined_color)\n",
    "    combined_binary[(combined_color == 1) & ((combined_thresh == 1) | (s_binary == 1))] = 1\n",
    "    \n",
    "    # Apply a triangle mask\n",
    "    mask = np.zeros_like(combined_binary)\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "    mask_resion = [np.array([[0, h-1], [w//2, h//2],[w-1, h-1]], dtype=np.int32)]\n",
    "    cv2.fillPoly(mask, mask_resion, 1)\n",
    "    \n",
    "    combined_mask = cv2.bitwise_and(combined_binary, mask)\n",
    "    \n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "raw",
   "id": "438bc17c",
   "metadata": {},
   "source": [
    "imgs = os.listdir('output_images/distortion_correction/')\n",
    "\n",
    "for img in imgs:\n",
    "    undist_img = mpimg.imread('output_images/distortion_correction/' + img)\n",
    "    \n",
    "    combined_mask = combined_color_threshold(undist_img)\n",
    "    \n",
    "    mpimg.imsave('output_images/binary/' + img, combined_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c25ce9",
   "metadata": {},
   "source": [
    "## birds-eye view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde358fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def birds_eye(image):\n",
    "#     offset = 0\n",
    "    x = image.shape[1]\n",
    "    y = image.shape[0]\n",
    "    \n",
    "#     src = np.float32([\n",
    "#         [530, 497],\n",
    "#         [0, 670],\n",
    "#         [1280, 670],\n",
    "#         [720, 450]\n",
    "#     ])\n",
    "    \n",
    "#     dst = np.float32([\n",
    "#         [offset, offset],\n",
    "#         [offset, y-offset], \n",
    "#         [x-offset, y-offset], \n",
    "#         [x-offset, offset]\n",
    "#     ])\n",
    "\n",
    "\n",
    "    src = np.float32(\n",
    "        [[(x / 2) - 63, y / 2 + 100],\n",
    "        [((x / 6) - 20), y],\n",
    "        [(x * 5 / 6) + 60, y],\n",
    "        [(x / 2 + 65), y / 2 + 100]])\n",
    "    dst = np.float32(\n",
    "        [[(x / 4), 0],\n",
    "        [(x / 4), y],\n",
    "        [(x * 3 / 4), y],\n",
    "        [(x * 3 / 4), 0]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(image, M, [x, y])\n",
    "    \n",
    "    return warped, M, M_inv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aa41f95",
   "metadata": {},
   "source": [
    "imgs = os.listdir('output_images/binary/')\n",
    "\n",
    "for img in imgs:\n",
    "    binary_img = mpimg.imread('output_images/binary/' + img)\n",
    "    birds_eye_img, M, M_inv = birds_eye(binary_img)\n",
    "    \n",
    "    mpimg.imsave('output_images/birds_eye/' + img, birds_eye_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5671a",
   "metadata": {},
   "source": [
    "## Lane boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0679bb",
   "metadata": {},
   "source": [
    "### First frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(image):\n",
    "    bottom_half = image[image.shape[0]//2:,:]\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "\n",
    "def find_lane_pixels(image):\n",
    "    # number of sliding windows\n",
    "    windows = 9\n",
    "    # the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # minimum number of pixels found to recenter window\n",
    "    minpix = 5\n",
    "    \n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    out_img = np.dstack((image, image, image))\n",
    "    \n",
    "    histogram = hist(image)\n",
    "    \n",
    "    midpoint = int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Current positions to be updated later for each window in windows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = int(image.shape[0]//windows)\n",
    "    #x and y positions of all nonzero pixels in the image\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    for window in range(windows):\n",
    "        # window boundaries in x and y (and right and left)\n",
    "        win_y_low = image.shape[0] - (window+1)*window_height\n",
    "        win_y_high = image.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If pixels > minpix, recentering next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(image):\n",
    "    # lane pixels\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(image)\n",
    "    \n",
    "    # fitting second order polynomial\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generating x and y values for plotting\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0])\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    # Visualization\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        cv2.circle(out_img, (int(left_fitx[i]), int(ploty[i])), 1, (255,255,0))\n",
    "        cv2.circle(out_img, (int(right_fitx[i]), int(ploty[i])), 1, (255,255,0))\n",
    "\n",
    "    return out_img, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "raw",
   "id": "369fdbed",
   "metadata": {},
   "source": [
    "imgs = os.listdir('output_images/birds_eye/')\n",
    "\n",
    "# for img in imgs:\n",
    "#     birds_eye_img = mpimg.imread('output_images/birds_eye/' + img)\n",
    "#     fit_polynomial_img = fit_polynomial(birds_eye_img)\n",
    "    \n",
    "#     mpimg.imsave('output_images/fit_polynomial/' + img, fit_polynomial_img)\n",
    "    \n",
    "#     mpimg.imsave('output_images/fit_polynomial/' + img, fit_img)\n",
    "# birds_eye_img = mpimg.imread('output_images/birds_eye/' + imgs[0])\n",
    "birds_eye_img = mpimg.imread('output_images/birds_eye/' + 'straight_lines1.jpg')\n",
    "fit_img = fit_polynomial(birds_eye_img)[0]\n",
    "plt.imshow(fit_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e2cf2",
   "metadata": {},
   "source": [
    "### Search in a margin around the previous lane line position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly(image, leftx, lefty, rightx, righty):\n",
    "    img_shape = image.shape\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "\n",
    "def line_average(prev, new):\n",
    "    # Number of frames to consider\n",
    "    frames = 12\n",
    "    \n",
    "    if new is None:\n",
    "        if len(prev) == 0:\n",
    "            return prev, None\n",
    "        else:\n",
    "            return prev, prev[-1]\n",
    "        \n",
    "    else:\n",
    "        if len(prev) < frames:\n",
    "            prev.append(new)\n",
    "            return prev, new\n",
    "        else:\n",
    "            prev[0:frames-1] = prev[1:]\n",
    "            prev[frames-1] = new\n",
    "            new = np.zeros_like(new)\n",
    "            for i in range(frames):\n",
    "                new += prev[i]\n",
    "                \n",
    "            new /= frames\n",
    "            return prev, new\n",
    "\n",
    "\n",
    "def search_around_poly(image, left_fit=None, right_fit=None, prev_left=[], prev_right=[], mean=0):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    margin = 100\n",
    "    \n",
    "    # In case there is no fitted line\n",
    "    if left_fit is None or right_fit is None:\n",
    "        return fit_polynomial(image)\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # In case there is no fitted line\n",
    "    if leftx.size == 0 or rightx.size == 0:\n",
    "        return fit_polynomial(image)\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(image, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    # Finding the mean\n",
    "    current_mean = np.mean(right_fitx - left_fitx)\n",
    "    \n",
    "    if mean == 0:\n",
    "        mean = current_mean\n",
    "        \n",
    "    if current_mean < 0.7*mean or current_mean > 1.3*mean:\n",
    "        if len(prev_left) == 0 and len(prev_right) == 0:\n",
    "            return fit_polynomial(image)\n",
    "        else:\n",
    "            left_fitx = prev_left[-1]\n",
    "            right_fitx = prev_right[-1]\n",
    "              \n",
    "    else:\n",
    "        prev_left, left_fitx = line_average(prev_left, left_fitx)\n",
    "        prev_right, right_fitx = line_average(prev_right, right_fitx)\n",
    "        \n",
    "        current_mean = np.mean(right_fitx - left_fitx)\n",
    "        mean = 0.9*mean + 0.1*current_mean\n",
    "    \n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((image, image, image))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    for i in range(image.shape[0]):\n",
    "        cv2.circle(result, (int(left_fitx[i]), int(ploty[i])), 1, (255,255,0))\n",
    "        cv2.circle(result, (int(right_fitx[i]), int(ploty[i])), 1, (255,255,0))\n",
    "    \n",
    "    return result, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "209842c5",
   "metadata": {},
   "source": [
    "imgs = os.listdir('output_images/birds_eye/')\n",
    "\n",
    "# for img in imgs:\n",
    "#     fit_img = mpimg.imread('output_images/birds_eye/' + img)\n",
    "#     search_fit_img = search_around_poly(fit_img)\n",
    "    \n",
    "#     mpimg.imsave('output_images/search_fit/' + img, search_fit_img)\n",
    "\n",
    "fit_img = mpimg.imread('output_images/birds_eye/' + imgs[3])\n",
    "search_fit_img, left_fitx, right_fitx = search_around_poly(fit_img, left_fit, right_fit)\n",
    "plt.imshow(search_fit_img)\n",
    "# mpimg.imsave('output_images/search_fit/' + img, search_fit_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac79df",
   "metadata": {},
   "source": [
    "## Measuring curvature and car position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature(image, leftx, rightx):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    img_shape = image.shape\n",
    "    \n",
    "    ploty = np.linspace(0, img_shape[0] - 1, img_shape[0])\n",
    "    \n",
    "    xm_per_pix=3.7/700\n",
    "    ym_per_pix = 15.0/img_shape[0]\n",
    "    \n",
    "    # Reverse to match top-to-bottom in y\n",
    "    leftx = leftx[::-1]\n",
    "    rightx = rightx[::-1]  \n",
    "    \n",
    "    # second order polynomial to pixel positions\n",
    "    left_fit = np.polyfit(ploty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit = np.polyfit(ploty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # new polynomials to x,y in world space\n",
    "    y_eval = np.max(ploty)\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "\n",
    "def car_position(image, leftx, rightx, xm_per_pix=3.7/700):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    img_shape = image.shape\n",
    "        \n",
    "    ## Car position\n",
    "    car_pos = (leftx[-1] + rightx[-1])/2 \n",
    "    position = (img_shape[1]//2 - car_pos) * xm_per_pix\n",
    "\n",
    "    return position"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca1104d3",
   "metadata": {},
   "source": [
    "imgs = os.listdir('output_images/search_fit/')\n",
    "\n",
    "search_fit_img = mpimg.imread('output_images/search_fit/' + imgs[3])\n",
    "left_curverad, right_curverad = measure_curvature(search_fit_img, leftx, rightx)\n",
    "position = car_position(search_fit_img, leftx, rightx)\n",
    "print(left_curverad, right_curverad, position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3d938",
   "metadata": {},
   "source": [
    "## Inverse Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_on_image(image, warped_img, left_fitx, right_fitx, M_inv, left_curverad, right_curverad, position):\n",
    "#     gray = cv2.cvtColor(warped_img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0])\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Display information on image\n",
    "    left_curvature = \"Left  Curvature: {:.2f} m\".format(left_curverad) \n",
    "    right_curvature = \"Right  Curvature: {:.2f} m\".format(right_curverad)\n",
    "    car_position = \"Car offset: {:.2f} m\".format(position)\n",
    "    cv2.putText(newwarp, left_curvature, (100,50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255),\n",
    "                5,  lineType = cv2.LINE_AA)\n",
    "    cv2.putText(newwarp, right_curvature, (100,120), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255),\n",
    "                5,  lineType = cv2.LINE_AA)\n",
    "    cv2.putText(newwarp, car_position, (100,190), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255),\n",
    "                5,  lineType = cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    return cv2.addWeighted(image, 1, newwarp, 0.3, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca44646c",
   "metadata": {},
   "source": [
    "imgs = os.listdir('output_images/search_fit/')\n",
    "orginal_imgs = os.listdir('test_images')\n",
    "\n",
    "search_fit_img = mpimg.imread('output_images/search_fit/' + imgs[0])\n",
    "image = mpimg.imread('test_images/' + orginal_imgs[4])\n",
    "\n",
    "unwarped_img = draw_on_image(image, search_fit_img, left_fitx, right_fitx, M_inv, left_curverad, right_curverad, position)\n",
    "plt.imshow(unwarped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1635cd",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c95d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # Initialization\n",
    "        self.left_fit = None\n",
    "        self.left_fitx = None\n",
    "        self.right_fit = None\n",
    "        self.right_fitx = None\n",
    "        self.prev_left = []\n",
    "        self.prev_right = []\n",
    "        self.mean = 0\n",
    "        \n",
    "        # Camera calibration\n",
    "        self.mtx, self.dist = calibration()\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        # Distortion correction\n",
    "        undist_img = distortion_correction(image, self.mtx, self.dist)\n",
    "        \n",
    "        # Threshold binary\n",
    "        combined_mask_img = combined_color_threshold(undist_img)\n",
    "        \n",
    "        # Prespective transform\n",
    "        birds_eye_img, M, M_inv = birds_eye(combined_mask_img)\n",
    "        \n",
    "        # Lane boundry\n",
    "        fit_img, self.left_fit, self.right_fit = fit_polynomial(birds_eye_img)\n",
    "        search_img, self.left_fitx, self.right_fitx = search_around_poly(birds_eye_img, self.left_fit, self.right_fit)\n",
    "        \n",
    "        # Curvature and car position\n",
    "        left_curverad, right_curverad = measure_curvature(birds_eye_img, self.left_fitx, self.right_fitx)\n",
    "        position = car_position(birds_eye_img, self.left_fitx, self.right_fitx)\n",
    "        \n",
    "        # Inverse transform\n",
    "        result = draw_on_image(undist_img, birds_eye_img, self.left_fitx, self.right_fitx,\n",
    "                      M_inv, left_curverad, right_curverad, position)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = Line()\n",
    "\n",
    "imgs = os.listdir('test_images')\n",
    "\n",
    "for img in imgs:\n",
    "    test_img = mpimg.imread('test_images/' + img)\n",
    "    result = line(test_img)\n",
    "    \n",
    "    mpimg.imsave('output_images/pipeline/' + img, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "video_frame = Line()\n",
    "\n",
    "clip1 = VideoFileClip('./project_video.mp4')\n",
    "white_clip = clip1.fl_image(video_frame)\n",
    "%time white_clip.write_videofile('./output_videos/project_video_output.mp4', audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8217dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
